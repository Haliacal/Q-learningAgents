{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import time\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import FrameStackObservation as FrameStack\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "import ale_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# if GPU is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_stacked = 4\n",
    "\n",
    "\n",
    "gym.register_envs(ale_py)\n",
    "env = FrameStack(gym.make(\"ALE/Pong-v5\"), frames_stacked)\n",
    "\n",
    "num_actions = env.action_space.n\n",
    "frame_shape = env.observation_space.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_shape, num_outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.num_outputs = num_outputs\n",
    "    \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(self.input_shape[0], 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        conv_output_len = int(np.prod(self.conv_layers(torch.zeros(1, *input_shape)).size()))\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(conv_output_len, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, self.num_outputs)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        conv_out = self.conv_layers(x).view(x.size()[0], -1)\n",
    "        return self.fc_layers(conv_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 83, 72])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(frame):\n",
    "    processed = np.mean(np.array(frame)/255.0,3, np.float32, keepdims = False, )\n",
    "    cropped = processed[:,32:198,8:-8]\n",
    "    result = cropped[:,::2,::2]\n",
    "    return torch.from_numpy(result).float().to(device)\n",
    "\n",
    "args = env.reset()\n",
    "state = args[0]\n",
    "MAXLIVES = args[-1]['lives']\n",
    "\n",
    "input_shape = preprocess(state).shape\n",
    "\n",
    "input_shape\n",
    "\n",
    "args = env.reset()\n",
    "state = args[0]\n",
    "MAXLIVES = args[-1]['lives']\n",
    "\n",
    "input_shape = preprocess(state).shape\n",
    "\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2318a235180>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for _ in range(10): state, *_ = env.step(1)\n",
    "plt.imshow(state[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2318c488610>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(preprocess(state)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN(input_shape=input_shape, num_outputs=num_actions).to(device)\n",
    "\n",
    "# Create policy and target network.\n",
    "policy_net = DQN(input_shape=input_shape, num_outputs=num_actions).to(device)\n",
    "target_net = DQN(input_shape=input_shape, num_outputs=num_actions).to(device)\n",
    "\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "with torch.no_grad():\n",
    "    policy_net(preprocess(state).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity, batchSize):\n",
    "        self.maxCapacity = capacity\n",
    "        self.stateMemory = []\n",
    "        self.actionMemory = []\n",
    "        self.rewardMemory = []\n",
    "        self.nextStateMemory = []\n",
    "        self.batchSize = batchSize\n",
    "        self.currentMemorySize = 0\n",
    "\n",
    "    def push(self, state, action, reward, nextState):\n",
    "        self.stateMemory.append(state)\n",
    "        self.actionMemory.append(action)\n",
    "        self.rewardMemory.append(reward)\n",
    "        self.nextStateMemory.append(nextState)\n",
    "\n",
    "        self.currentMemorySize += 1\n",
    "\n",
    "        if(self.currentMemorySize > self.maxCapacity):\n",
    "            self.stateMemory.pop(0)\n",
    "            self.actionMemory.pop(0)\n",
    "            self.rewardMemory.pop(0)\n",
    "            self.nextStateMemory.pop(0)\n",
    "\n",
    "\n",
    "    def sample(self):\n",
    "        return random.sample(range(self.currentMemorySize), self.batchSize)\n",
    "\n",
    "    def replay(self):\n",
    "\n",
    "        if(self.currentMemorySize < self.batchSize): return\n",
    "\n",
    "        minibatchIndices = self.sample()\n",
    "\n",
    "\n",
    "\n",
    "        stateBatch = torch.cat(list(itemgetter(*minibatchIndices)(self.stateMemory))).to(device)\n",
    "        actionBatch = torch.cat(list(itemgetter(*minibatchIndices)(self.actionMemory))).to(device)\n",
    "        rewardBatch = torch.cat(list(itemgetter(*minibatchIndices)(self.actionMemory))).to(device).squeeze(1)\n",
    "\n",
    "\n",
    "        nextStateBatchList = list(itemgetter(*minibatchIndices)(self.nextStateMemory))\n",
    "        nonFinalNextStates = []\n",
    "        nonFinalIndices = []\n",
    "\n",
    "        for s in nextStateBatchList:\n",
    "            if s is not None:\n",
    "                nonFinalNextStates.append(s)\n",
    "                nonFinalIndices.append(True)\n",
    "\n",
    "            else:\n",
    "                nonFinalIndices.append(False)\n",
    "\n",
    "        nonFinalNextStates = torch.cat(nonFinalNextStates).to(device)\n",
    "\n",
    "        nonFinalNextStateValues = torch.zeros(self.batchSize, device=device)\n",
    "        nonFinalIndices = torch.tensor(tuple(nonFinalIndices), device=device, dtype=torch.bool)\n",
    "\n",
    "\n",
    "\n",
    "        state_action_values = policy_net(stateBatch).gather(1, actionBatch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            nonFinalNextStateValues[nonFinalIndices] = target_net(nonFinalNextStates).max(1).values\n",
    "\n",
    "        # Compute the expected Q values\n",
    "        expected_state_action_values = (nonFinalNextStateValues*gamma) + rewardBatch\n",
    "\n",
    "\n",
    "        # Compute Huber loss\n",
    "        optimiser.zero_grad()\n",
    "        criterion = nn.SmoothL1Loss()\n",
    "\n",
    "        loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "        #loss.requires_grad = True\n",
    "        loss.backward()\n",
    "        # Register backward hook\n",
    "        for p in policy_net.parameters(): p.grad.data.clamp_(-1, 1)\n",
    "        optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "alpha = 1e-4  # learning rate\n",
    "gamma = 0.99 # Discount fator\n",
    "\n",
    "# Optimiser and loss function\n",
    "optimiser = optim.Adam(policy_net.parameters(), lr=alpha, amsgrad=True)\n",
    "\n",
    "# Epsilon\n",
    "epsilon = 0.9\n",
    "decay = 0.995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('state', 'action', 'reward', 'next_state'))\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity, batchSize):\n",
    "        self.maxCapacity = capacity\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "        self.batchSize = batchSize\n",
    "\n",
    "    def push(self, state, action, reward, nextState, done):\n",
    "        if(done): return        \n",
    "        self.memory.append(Transition(state, action, reward, nextState))\n",
    "\n",
    "    def sample(self):\n",
    "        return random.sample(self.memory, self.batchSize)\n",
    "\n",
    "    def replay(self):\n",
    "        \n",
    "        if(len(self.memory) < self.batchSize): return \n",
    "        \n",
    "        minibatch = self.sample()\n",
    "        \n",
    "        batch = Transition(*zip(*minibatch))\n",
    "\n",
    "\n",
    "        non_final_next_states = torch.cat([s for s in batch.next_state])\n",
    "        state_batch = torch.cat(batch.state)\n",
    "        action_batch = torch.cat(batch.action)\n",
    "        reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    \n",
    "        state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            next_state_values = target_net(non_final_next_states).max(1).values\n",
    "            \n",
    "        # Compute the expected Q values\n",
    "        expected_state_action_values = (next_state_values*gamma) + reward_batch\n",
    "\n",
    "        # Compute Huber loss\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "        criterion = nn.HuberLoss()\n",
    "        loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "        #loss.requires_grad = True\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "        optimiser.step()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replay memory parameters\n",
    "capacity = 1000\n",
    "batchSize = 32\n",
    "memory = ReplayMemory(capacity=capacity, batchSize=batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Total Reward: 0.0\n",
      "Episode: 100, Total Reward: 0.0\n",
      "Episode: 200, Total Reward: 0.0\n",
      "Episode: 300, Total Reward: 0.0\n",
      "Episode: 400, Total Reward: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[272], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m memory\u001b[38;5;241m.\u001b[39mpush(state, action,torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28mmax\u001b[39m(reward,\u001b[38;5;241m1\u001b[39m)]) , nextState, terminated \u001b[38;5;129;01mor\u001b[39;00m truncated \u001b[38;5;129;01mor\u001b[39;00m info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlives\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     39\u001b[0m rewards \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[1;32m---> 40\u001b[0m \u001b[43mmemory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m state \u001b[38;5;241m=\u001b[39m nextState\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m((timesteps\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m%\u001b[39mupdateRate \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m): target_net\u001b[38;5;241m.\u001b[39mload_state_dict(policy_net\u001b[38;5;241m.\u001b[39mstate_dict())\n",
      "Cell \u001b[1;32mIn[267], line 47\u001b[0m, in \u001b[0;36mReplayMemory.replay\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     45\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     46\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_value_(policy_net\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m---> 47\u001b[0m \u001b[43moptimiser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joshu\\anaconda3\\envs\\rl\\lib\\site-packages\\torch\\optim\\optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    485\u001b[0m             )\n\u001b[1;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\joshu\\anaconda3\\envs\\rl\\lib\\site-packages\\torch\\optim\\optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\joshu\\anaconda3\\envs\\rl\\lib\\site-packages\\torch\\optim\\adam.py:223\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    211\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    213\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    214\u001b[0m         group,\n\u001b[0;32m    215\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    220\u001b[0m         state_steps,\n\u001b[0;32m    221\u001b[0m     )\n\u001b[1;32m--> 223\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\joshu\\anaconda3\\envs\\rl\\lib\\site-packages\\torch\\optim\\optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\joshu\\anaconda3\\envs\\rl\\lib\\site-packages\\torch\\optim\\adam.py:784\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    782\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 784\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joshu\\anaconda3\\envs\\rl\\lib\\site-packages\\torch\\optim\\adam.py:379\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m    378\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mlerp_(grad, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[1;32m--> 379\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[0;32m    382\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "episodes = 10000 \n",
    "verbose = True\n",
    "steps = 0\n",
    "verboseEpisode = 100\n",
    "updateRate = 10\n",
    "timesteps = 0\n",
    "TAU = 0.005\n",
    "\n",
    "\n",
    "for episode in range(episodes):\n",
    "    state = env.reset()[0]\n",
    "    state, reward, terminated, truncated, info = env.step(1)\n",
    "    rewards = 0\n",
    "    terminated, truncated = False, False\n",
    "    state = preprocess(state).unsqueeze(0)\n",
    "    \n",
    "\n",
    "\n",
    "    while not terminated and not truncated and info['lives'] == 5:\n",
    "        \n",
    "        # Epsilon\n",
    "        #epsilon = EPS_END + (EPS_START - EPS_END) * math.exp(-steps / EPS_DECAY)\n",
    "        steps += 1\n",
    "        \n",
    "        # Explore\n",
    "        if(random.uniform(0,1) <= epsilon): action = torch.tensor([[env.action_space.sample()]])\n",
    "        \n",
    "        # Exploit\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                q_values = policy_net(state)\n",
    "                action = q_values.max(1).indices.view(1, 1)\n",
    "       \n",
    "        nextState, reward, terminated, truncated, info = env.step(action.item())\n",
    "        nextState = preprocess(nextState).unsqueeze(0)\n",
    "        \n",
    "        if(terminated or truncated or info['lives'] < 5): nextState = False\n",
    "        \n",
    "        memory.push(state, action,torch.tensor([max(reward,1)], device=device) , nextState, terminated or truncated or info['lives'] < 5)\n",
    "        rewards += reward\n",
    "        memory.replay()\n",
    "        \n",
    "        state = nextState\n",
    "        target_net_state_dict = target_net.state_dict()\n",
    "        policy_net_state_dict = policy_net.state_dict()\n",
    "        for key in policy_net_state_dict:\n",
    "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "        target_net.load_state_dict(target_net_state_dict)\n",
    "        \n",
    "        if epsilon > 0.05:\n",
    "            epsilon *= decay\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    if(verbose and episode%verboseEpisode == 0): print(f\"Episode: {episode}, Total Reward: {rewards}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(policy_net.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN(input_shape=input_shape, num_outputs=num_actions)\n",
    "model.load_state_dict(torch.load('model.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained agent\n",
    "total_rewards = []\n",
    "num_episodes_eval = 10\n",
    "for _ in range(num_episodes_eval):\n",
    "    state = env.reset()[0]\n",
    "    rewards = 0\n",
    "    terminated, truncated = False, False\n",
    "    while not terminated and not truncated:\n",
    "        action = torch.argmax(model(preprocess(state).unsqueeze(0))).item()\n",
    "        next_state, reward, terminated, truncated, info = env.step(action)\n",
    "        state = next_state\n",
    "        rewards += reward\n",
    "        \n",
    "    total_rewards.append(rewards)\n",
    "\n",
    "print(f\"Average Total Reward (Evaluation): {np.mean(total_rewards)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# watch trained agent\n",
    "env = FrameStack(gym.make(\"ALE/Galaxian-v5\", render_mode='human'), frames_stacked)\n",
    "\n",
    "state = env.reset()[0]\n",
    "\n",
    "ACTIONS = [\"NOOP\", \"Fire\", \"Right\", \"Left\", \"Right Fire\", \"Left Fire\"]\n",
    "\n",
    "rewards = 0\n",
    "terminated, truncated = False, False\n",
    "steps = 0\n",
    "\n",
    "while not terminated and not truncated:\n",
    "\n",
    "    if(steps < 10):\n",
    "        action = env.action_space.sample()\n",
    "        steps += 1\n",
    "    \n",
    "    else: action = torch.argmax(model(preprocess(state).unsqueeze(0))).item()\n",
    "    \n",
    "    next_state, reward, terminated, truncated, info = env.step(action)\n",
    "    print(ACTIONS[action], reward ,terminated or truncated)\n",
    "    \n",
    "    state = next_state\n",
    "    \n",
    "    rewards += reward\n",
    "    \n",
    "    env.render()\n",
    "    \n",
    "    time.sleep(0.01)\n",
    "\n",
    "time.sleep(3)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
