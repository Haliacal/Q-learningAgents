{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "h0x-2eDo0BjB"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import time\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import FrameStackObservation as FrameStack\n",
    "from gymnasium.wrappers import AtariPreprocessing\n",
    "from gymnasium.wrappers import NumpyToTorch\n",
    "from gymnasium.wrappers import RecordEpisodeStatistics\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from collections import namedtuple, deque\n",
    "from operator import itemgetter\n",
    "\n",
    "import ale_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HEGJ7ADy0BjE"
   },
   "outputs": [],
   "source": [
    "# if GPU is to be used\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() else\n",
    "    \"mps\" if torch.backends.mps.is_available() else\n",
    "    \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PzlvTaW40BjF"
   },
   "outputs": [],
   "source": [
    "frames_stacked = 4\n",
    "\n",
    "gym.register_envs(ale_py)\n",
    "\n",
    "#game = \"ALE/Breakout-v5\"\n",
    "game = \"ALE/Pong-v5\"\n",
    "\n",
    "terminal_on_life_loss = False\n",
    "scale_obs = True\n",
    "\n",
    "env = NumpyToTorch(FrameStack(AtariPreprocessing(RecordEpisodeStatistics(gym.make(game)), frame_skip=1, terminal_on_life_loss=terminal_on_life_loss, scale_obs=scale_obs), frames_stacked), device=device)\n",
    "\n",
    "num_actions = env.action_space.n\n",
    "frame_shape = env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6U2kTBCA0BjF"
   },
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_shape, num_outputs):\n",
    "        super(DQN, self).__init__()\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "        self.num_outputs = num_outputs\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(self.input_shape[0], 32, kernel_size=8, stride=4),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        conv_output_len = int(np.prod(self.conv_layers(torch.zeros(1, *input_shape)).size()))\n",
    "\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(conv_output_len,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, self.num_outputs)\n",
    "        )\n",
    "        conv_test = self.conv_layers(torch.zeros(1, *input_shape))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        conv_out = self.conv_layers(x)\n",
    "        return self.fc_layers(conv_out.flatten(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "thEu_49S0BjF"
   },
   "outputs": [],
   "source": [
    "args = env.reset()\n",
    "state = args[0]\n",
    "input_shape = state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "1VSVKCQL0BjG",
    "outputId": "ab65469d-4e94-4f9f-85b6-90963eb72705"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1808edec700>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for _ in range(10): state, *_ = env.step(1)\n",
    "plt.imshow(state[3].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KASJ1IZI0BjH",
    "outputId": "5748aeed-4496-4b1f-b9a2-c43f7c125c8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0516, -0.0602,  0.0273, -0.0215, -0.0132,  0.1484]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DQN(input_shape=input_shape, num_outputs=num_actions)\n",
    "\n",
    "# Create policy and target network.\n",
    "policy_net = DQN(input_shape=input_shape, num_outputs=num_actions).to(device)\n",
    "target_net = DQN(input_shape=input_shape, num_outputs=num_actions).to(device)\n",
    "\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "with torch.no_grad():\n",
    "    stateValues = policy_net(state.unsqueeze(0))\n",
    "\n",
    "stateValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "f9AuCwJ20BjH"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "alpha = 1e-4  # learning rate\n",
    "gamma = 0.99 # Discount fator\n",
    "\n",
    "# Optimiser and loss function\n",
    "optimiser = optim.Adam(policy_net.parameters(), lr=alpha, amsgrad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6RI9YS_q0BjH"
   },
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('state', 'action', 'reward', 'next_state'))\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity, batchSize):\n",
    "        self.maxCapacity = capacity\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "        self.batchSize = batchSize\n",
    "\n",
    "    def push(self, state, action, reward, nextState):\n",
    "        self.memory.append(Transition(state, action, reward, nextState))\n",
    "\n",
    "    def sample(self):\n",
    "        return random.sample(self.memory, self.batchSize)\n",
    "\n",
    "    def replay(self):\n",
    "\n",
    "        if(len(self.memory) < self.batchSize): return\n",
    "\n",
    "        minibatch = self.sample()\n",
    "\n",
    "        batch = Transition(*zip(*minibatch))\n",
    "\n",
    "        non_final_mask = torch.tensor(tuple(map(lambda s: s is not None, batch.next_state)), device=device, dtype=torch.bool)\n",
    "\n",
    "        non_final_next_states = torch.cat([s for s in batch.next_state if s is not None]).to(device)\n",
    "        state_batch = torch.cat(batch.state).to(device)\n",
    "        action_batch = torch.cat(batch.action).to(device)\n",
    "        reward_batch = torch.cat(batch.reward).to(device)\n",
    "\n",
    "        next_state_values = torch.zeros(self.batchSize, device=device)\n",
    "        policy_actions = torch.argmax(policy_net(non_final_next_states), dim=1).unsqueeze(1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            next_state_values[non_final_mask] = target_net(non_final_next_states).gather(1, policy_actions).squeeze(1)\n",
    "\n",
    "\n",
    "        state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "\n",
    "\n",
    "        # Compute the expected Q values\n",
    "        expected_state_action_values = (next_state_values*gamma) + reward_batch\n",
    "\n",
    "\n",
    "        # Compute Huber loss\n",
    "        optimiser.zero_grad()\n",
    "        criterion = nn.HuberLoss()\n",
    "        criterion.sizeAverage = False\n",
    "        loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "        #loss.requires_grad = True\n",
    "        loss.backward()\n",
    "        \n",
    "        # Register backward hook\n",
    "        for p in policy_net.parameters(): p.grad.data.clamp_(-1, 1)\n",
    "        optimiser.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "53o57oM00BjI"
   },
   "outputs": [],
   "source": [
    "# Replay memory parameters\n",
    "capacity = 100000\n",
    "batchSize = 32\n",
    "memory = ReplayMemory(capacity=capacity, batchSize=batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "id": "9ydtaTrM0BjI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0022, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0028, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0020, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0015, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0021, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0019, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0022, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0013, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0151, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0154, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0144, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0134, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0146, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0125, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0039, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0043, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0034, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0086, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0027, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0118, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0027, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0086, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0080, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0052, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0031, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0036, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0033, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0042, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0071, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0067, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0075, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0055, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0025, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0031, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0039, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0037, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0066, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0061, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0052, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0038, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0030, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0024, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0009, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0008, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0144, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0029, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0147, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0039, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0154, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0026, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0173, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0010, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0057, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0027, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0027, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0016, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0017, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0014, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0138, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0018, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0126, grad_fn=<HuberLossBackward0>)\n",
      "tensor(0.0023, grad_fn=<HuberLossBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 50\u001b[0m\n\u001b[0;32m     46\u001b[0m rewards \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[0;32m     47\u001b[0m memory\u001b[38;5;241m.\u001b[39mpush(state, action, torch\u001b[38;5;241m.\u001b[39mtensor([reward], device\u001b[38;5;241m=\u001b[39mdevice), nextState)\n\u001b[1;32m---> 50\u001b[0m \u001b[43mmemory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m state \u001b[38;5;241m=\u001b[39m nextState\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(steps\u001b[38;5;241m%\u001b[39mupdateEvery \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m): target_net\u001b[38;5;241m.\u001b[39mload_state_dict(policy_net\u001b[38;5;241m.\u001b[39mstate_dict())\n",
      "Cell \u001b[1;32mIn[12], line 31\u001b[0m, in \u001b[0;36mReplayMemory.replay\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     28\u001b[0m reward_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(batch\u001b[38;5;241m.\u001b[39mreward)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     30\u001b[0m next_state_values \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatchSize, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m---> 31\u001b[0m policy_actions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(\u001b[43mpolicy_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnon_final_next_states\u001b[49m\u001b[43m)\u001b[49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     34\u001b[0m     next_state_values[non_final_mask] \u001b[38;5;241m=\u001b[39m target_net(non_final_next_states)\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m1\u001b[39m, policy_actions)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\joshu\\anaconda3\\envs\\rl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\joshu\\anaconda3\\envs\\rl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[4], line 33\u001b[0m, in \u001b[0;36mDQN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 33\u001b[0m     conv_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_layers(conv_out\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\joshu\\anaconda3\\envs\\rl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\joshu\\anaconda3\\envs\\rl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\joshu\\anaconda3\\envs\\rl\\lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\joshu\\anaconda3\\envs\\rl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\joshu\\anaconda3\\envs\\rl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\joshu\\anaconda3\\envs\\rl\\lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joshu\\anaconda3\\envs\\rl\\lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "episodes = 2001\n",
    "verbose = True\n",
    "steps = 0\n",
    "verboseEpisode = 50\n",
    "timesteps = 0\n",
    "updateEvery = 1500\n",
    "\n",
    "EPSILON_START=1.0\n",
    "EPSILON_END=0.02\n",
    "EPSILON_DECAY=10000\n",
    "\n",
    "episodeRewards = []\n",
    "os.makedirs('models', exist_ok=True)\n",
    "stats = {}\n",
    "\n",
    "for episode in range(episodes):\n",
    "  state, _ = env.reset()\n",
    "  rewards = 0\n",
    "  terminated, truncated = False, False\n",
    "  state = state.unsqueeze(0)\n",
    "\n",
    "  while not terminated and not truncated:\n",
    "\n",
    "    epsilon = np.interp(steps, [0, EPSILON_DECAY], [EPSILON_START, EPSILON_END])\n",
    "\n",
    "    # Explore\n",
    "    if(random.uniform(0,1) <= epsilon): action = torch.tensor([[env.action_space.sample()]], device=device)\n",
    "\n",
    "    # Exploit\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            q_values = policy_net(state)\n",
    "            action = torch.argmax(policy_net(state), dim=1).unsqueeze(0)\n",
    "\n",
    "    steps += 1\n",
    "\n",
    "    nextState, reward, terminated, truncated, info = env.step(action.item())\n",
    "    nextState = nextState.unsqueeze(0)\n",
    "\n",
    "    if(terminated or truncated):\n",
    "      nextState = None\n",
    "      stats[episode] = info\n",
    "    rewards += reward\n",
    "    memory.push(state, action, torch.tensor([reward], device=device), nextState)\n",
    "\n",
    "\n",
    "    memory.replay()\n",
    "\n",
    "    state = nextState\n",
    "\n",
    "    if(steps%updateEvery == 0): target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "\n",
    "  episodeRewards.append(rewards)\n",
    "  if(verbose and episode%verboseEpisode == 0):\n",
    "    #print(f\"Episode: {episode}, Current avg reward: {np.mean(episodeRewards[-verboseEpisode:])}\")\n",
    "    torch.save(target_net.state_dict(), 'models/model_'+str(episode)+'.pt')\n",
    "\n",
    "with open('stats.pkl', 'wb') as f:\n",
    "  pickle.dump(stats, f)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
